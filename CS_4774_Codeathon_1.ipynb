{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamHarless/Codeathon1/blob/main/CS_4774_Codeathon_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y4F-zuUGsq8"
      },
      "source": [
        "# Codeathon 1: Comparison of Regression Models on Housing Prices in Ames, Iowa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ85ee69G7m0"
      },
      "source": [
        "### CS 4774 Machine Learning - Department of Computer Science - University of Virginia\n",
        "![(Image Credit Boston.gov)](https://miro.medium.com/max/1000/1*WYZCnpM7bE3Wq4NNxx7jDA.jpeg)\n",
        "\n",
        "In this assignment, you will practice the 8 steps of an end-to-end ML project in the context of a **regression** problem in the [Ames Housing Dataset on Kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data). You will attempt to predict the housing prices in Ames, IA. For references, you may refer to my slides or the Google Colab if you need additional sample codes to help with your assignment. To get started, you will need to upload/copy the dataset (.csv) into the same Colab workspace.\n",
        "\n",
        "For deliverables, you must write code in Colab and submit the downloaded Jupyter Notebook file (.ipynb) to earn a total of 50 pts. You will gain points depending on how you perform in the following sections.\n",
        "\n",
        "*BONUS POINTS:* 10 bonus points will be given (as Extra credits) for those who score among the top-10 performance while following strictly the assignment guidelines. Best of luck to all!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXPheacSXZ2V"
      },
      "source": [
        "## Step 1: Big Picture and Setup\n",
        "Write a paragraph explaining the context of the problem in which you are trying to investigate. Your paragraph may frame the problem and objectives by answering the following questions:\n",
        "* What is the task: regression, classification, clustering, visualization?\n",
        "* What to expect, how to use, and how to benefit from this model?\n",
        "* What performance measure to evaluate?\n",
        "* How much data is available or should be collected?\n",
        "* What learning algorithm to be used?\n",
        "* How much effort is to be spent?\n",
        "* Verify the assumptions that have been made about the context"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The task is load data, understand/visualize data, clean data, then develop a maching learning model from it.\n",
        "This model will predict housing prices in ames iowa based on a number of features.\n",
        "RMSE will be used to evaluate the differences in actual vs expected price for the test data.\n",
        "Multiple learning algorithims like linear regression and decision trees will be used.\n"
      ],
      "metadata": {
        "id": "bqWBbTDi5dg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3N7qDVRXuNa"
      },
      "source": [
        "## Step 2: Load the Data\n",
        "We will assume that the data file is put into the same workspace on Colab. Then, you can write some code to load the CSV file and take a quick look at the dataset, and output the following:\n",
        "\n",
        " * How big is your dataset? (in terms of MB)\n",
        " * How many entries does it have?\n",
        " * How many features does it have?\n",
        " * Does it contain any categorical data?\n",
        " * Is there any missing values?\n",
        " * What are some basic statistics you can learn right away about this dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y4uclsoGRcM"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# To help you get started, a load function is provided below.\n",
        "# You will need to fill in the code under #TODO to make it work.\n",
        "def loadBostonHousingData():\n",
        "  # The column names are adopted from the dataset page on Kaggle\n",
        "  housing = pd.read_csv('train.csv')\n",
        "  return housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5cT4JBSYOS6"
      },
      "source": [
        "## Step 3. Discover and visualize the data to gain insights\n",
        "**Data Discovery:** Plot out all correlations among the features. You should notice some features are more correlated with your predicted value than others. This information will help you confirm the weights of your regression model later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqfralxMGqCt"
      },
      "source": [
        "# Your code to visualize the data here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr8UHps5Z0cF"
      },
      "source": [
        "##  Step 4: Data Preparation and Cleaning\n",
        "Since we can only use the \"train.csv\", you have to \"artificially\" split the data into training set, validation set, and test set. You may use the `train_test_split()` function *twice*: first is to split into train and test, then to split the train again into training and validation sets.\n",
        "\n",
        "Next, you need to construct the following:\n",
        "\n",
        "* **Data Cleaning:** If your dataset has some missing values, make sure you are able to fill those values with the `Imputer` class.\n",
        "\n",
        "* **Feature Scaling:** Your task is to call the `StandardScaler` to normalize the value of each feature.\n",
        "\n",
        "* **Transformation Pipeline:** More importantly, you will need to integrate the above operations into a `Pipeline` to process and transform the training data (via `fit_transform()`), then use the same pipeline to transform any validation and testing data (using `transform()` only)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju-kzr0LaFb_"
      },
      "source": [
        "# Your code check for missing values, feature scaling, and put all transformation into a pipeline here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ExMZjJgaZ7j"
      },
      "source": [
        "## Step 5: Model Selection\n",
        "You should use (at the minimum) the basic ML models which weâ€™ve covered: `LinearRegression`, `DecisionTreeRegressor`, `RandomForestRegressor`. Optionally, you may go for the extra miles by doing some research and try some more advanced models (ie. `Artificial Neural Networks`). You may use `RMSE` as the performance measure.\n",
        "\n",
        "You must use 5-fold CV on the data set to evaluate the performance of your models (following the sample codes on Colab 02).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waI2JEldacQF"
      },
      "source": [
        "# Try a few models here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFiwPfmZeK2i"
      },
      "source": [
        "## Step 6: Model Tuning\n",
        "\n",
        "In this step, you should attempt to use one of the provided tools for hyperparameter tuning: `GridSearchCV`, `RandomizedSearchCV` to identify the best set of hyperparameters for your model. After tweaking your models, you eventually should report the 5-fold CV RMSE of your tuned model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmXB7iTPdIuu"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3YvBnpUeSEH"
      },
      "source": [
        "## Step 7: Solution Presentation\n",
        "Now that you need to write a short memo of one paragraph to be read by a non-technical audience (ie. your manager/supervisor). Focus on answering the following:\n",
        "\n",
        "* How can you pitch your solution to this project?\n",
        "* What did you learn so far about the problem?\n",
        "* Is there any insight moving forward to improve the solution?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nu7XgXRee3R"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrRRoBcWeVju"
      },
      "source": [
        "## Step 8: Model Launching, Monitoring, and Updating\n",
        "You don't need to do anything for this step. However, in the real-world, this is an iterative process where you launch, monitor, and update your model (on the cloud).\n",
        "\n",
        "In case you get stuck in any step in the process, you may find some useful information from:\n",
        "\n",
        " * Consult my slides and/or the textbook\n",
        " * Talk to the TA, they are available and there to help you during their office hours\n",
        " * Come talk to me or email me <nn4pj@virginia.edu> with subject starting \"CS4774 Codeathon 1:...\".\n",
        "\n",
        "Best of luck and have fun!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzpq8NedeU-m"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}